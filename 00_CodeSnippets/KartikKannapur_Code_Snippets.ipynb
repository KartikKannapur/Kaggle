{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Code Snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T14:41:47.504208Z",
     "start_time": "2018-07-04T14:41:36.566792Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\karti\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.3.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.3rc1 (v3.6.3rc1:d8c174a, Sep 19 2017 16:39:51)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "# #Python Libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import statsmodels\n",
    "import pandas_profiling\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "import missingno as msno\n",
    "import math\n",
    "import sys\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# #sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# #sklearn - preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# #sklearn - metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# #XGBoost & LightGBM\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# #Missing value imputation\n",
    "from fancyimpute import KNN, MICE\n",
    "\n",
    "# #Hyperparameter Optimization\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "# #NLP\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "pd.options.display.max_columns = 150\n",
    "##################################################################\n",
    "# #Spark\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'C:/Users/karti/Spark/spark-2.3.0-bin-hadoop2.7/python/lib/py4j-0.10.6-src.zip'))\n",
    "\n",
    "filename=os.path.join(spark_home, 'python/pyspark/shell.py')\n",
    "exec(compile(open(filename, \"rb\").read(), filename, 'exec'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory Structure"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "/code\n",
    "/data\n",
    "/submissions\n",
    "/transformed_data\n",
    "README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T01:22:53.528447Z",
     "start_time": "2018-05-24T01:22:53.523487Z"
    }
   },
   "source": [
    "# EDA - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Data Dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_project_train = pd.read_csv(\"../data/train.csv\")\n",
    "df_project_test = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "df_project_train.head()\n",
    "df_project_test.head()\n",
    "\n",
    "df_project_train.shape\n",
    "df_project_test.shape\n",
    "\n",
    "df_project_train.info()\n",
    "df_project_test.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #For both Train and Test datasets\n",
    "msno.matrix(df_train)\n",
    "msno.bar(df_train)\n",
    "msno.heatmap(df_train, figsize=(20,20))\n",
    "msno.dendrogram(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #At a column-level: Total number of missing data points, Percentage of missing data points\n",
    "def f_missing_data(data):\n",
    "    total = data.isnull().sum().sort_values(ascending = False)\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n",
    "    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "f_missing_data(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Total number of missing data points, for each column\n",
    "df_train.isnull().sum(axis = 0)\n",
    "\n",
    "# #Total number of missing data points across the entire dataset\n",
    "df_train.isnull().sum(axis = 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Missing value imputation via MICE\n",
    "df_train_imputed = MICE().complete(df_train)\n",
    "df_train_imputed = pd.DataFrame(df_train_imputed, columns=df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T01:25:04.664584Z",
     "start_time": "2018-05-24T01:25:04.660587Z"
    }
   },
   "source": [
    "## JOINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_A_B = df_A.merge(df_B, on=\"<column_name>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby + Transform - count, sum, mean, min, max, diff, lambda ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NEW_FEATURE'] = df.groupby('COLUMN_TO_GROUPBY')['COLUMN_TO_TRANSFORM'].transform('count')\n",
    "\n",
    "df['NEW_FEATURE'] = df.groupby('COLUMN_TO_GROUPBY')['COLUMN_TO_TRANSFORM'].transform(np.sum)\n",
    "df['NEW_FEATURE'] = df.groupby('COLUMN_TO_GROUPBY')['COLUMN_TO_TRANSFORM'].transform(np.mean)\n",
    "df['NEW_FEATURE'] = df.groupby('COLUMN_TO_GROUPBY')['COLUMN_TO_TRANSFORM'].transform(np.min)\n",
    "df['NEW_FEATURE'] = df.groupby('COLUMN_TO_GROUPBY')['COLUMN_TO_TRANSFORM'].transform(np.max)\n",
    "df['NEW_FEATURE'] = df.groupby('COLUMN_TO_GROUPBY')['COLUMN_TO_TRANSFORM'].transform(np.diff)\n",
    "\n",
    "df['NEW_FEATURE'] = df.groupby('COLUMN_TO_GROUPBY')['COLUMN_TO_TRANSFORM'].transform(lambda x:x+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby + Successive rows difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_bureau.copy()\n",
    "temp.sort_values(['COLUMN_TO_GROUPBY', 'COLUMN_TO_TRANSFORM'], inplace=True)\n",
    "temp['temp_successive_diff'] = temp.groupby('COLUMN_TO_GROUPBY')['COLUMN_TO_TRANSFORM'].transform(lambda ele: ele.diff())\n",
    "temp['FEATURE_SUCCESSIVE_DIFF_MEAN'] = temp.groupby('COLUMN_TO_GROUPBY')['temp_successive_diff'].transform(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Duplicate Rows at the end of Groupby Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['', 'LIST_OF_COLUMNS_TO_KEEP', '']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data Encoding - One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_ohe = pd.get_dummies(train_y)\n",
    "test_y_ohe = pd.get_dummies(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data Encoding - Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[var_col].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_categorical_columns = df_train.select_dtypes(['object']).columns\n",
    "for var_col in arr_categorical_columns:\n",
    "    df_train[var_col] = df_train[var_col].astype('category').cat.codes\n",
    "    df_train[var_col] = df_train[var_col].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data Encoding - Frequency Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = df.groupby('key').size()\n",
    "encoding = encoding/len(df)\n",
    "\n",
    "df['freq_encode'] = df['key'].map(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding on one column while group by on the parent column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.groupby(['PARENT_COL','CHILD_COL']).size()/df.groupby(['PARENT_COL']).size()\n",
    "temp_df = temp_df.to_frame().reset_index().rename(columns= {0: 'CHILD_COL_FREQENCODE'})\n",
    "df = pd.merge(df_bureau, temp_df[['PARENT_COL', 'CHILD_COL_FREQENCODE']], on=\"PARENT_COL\", how=\"left\", suffixes=('_parent', '_child'))\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note: Encode if categorical columns are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_train.columns\n",
    "# Separating out the features\n",
    "x = df_train.loc[:, features].values\n",
    "# Separating out the target\n",
    "y = df_train.loc[:,['TARGET']].values\n",
    "# Standardizing the features\n",
    "x = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "input_columns = df_train.columns\n",
    "input_columns = input_columns[input_columns != 'TARGET']\n",
    "target_column = 'TARGET'\n",
    "\n",
    "pca = PCA(0.99)\n",
    "pca.fit(df_train[input_columns])\n",
    "\n",
    "df_train_pca = pca.transform(df_train[input_columns])\n",
    "df_test_pca = pca.transform(df_test)\n",
    "\n",
    "df_train_pca = pd.DataFrame(data= df_train_pca)\n",
    "df_test_pca = pd.DataFrame(data= df_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(binary=True)\n",
    "\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding of the Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y)\n",
    "\n",
    "# #After making the prediction\n",
    "y_pred_invtransformed = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Train-Validation Split\n",
    "input_columns = df_train.columns\n",
    "input_columns = input_columns[input_columns != 'TARGET']\n",
    "target_column = 'TARGET'\n",
    "\n",
    "X = df_train[input_columns]\n",
    "y = df_train[target_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_test = model_rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.6,\n",
    "    'learning_rate': 0.01,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc', \n",
    "    'max_depth': 6,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = [(xgb.DMatrix(X_train, y_train), 'train'), (xgb.DMatrix(X_test, y_test), 'valid')]\n",
    "model = xgb.train(xgb_params, xgb.DMatrix(X_train, y_train), 270, watchlist, maximize=True, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = model.predict(xgb.DMatrix(df_test), ntree_limit=model.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission[\"PRED_COLUMN\"] =  df_test[\"PRED_COLUMN\"]\n",
    "submission[\"TARGET\"] =  df_predict\n",
    "\n",
    "submission.to_csv(\"../submissions/model.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost with Hyperparameter Optimization with Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = df_application_train.columns\n",
    "input_columns = input_columns[input_columns != 'TARGET']\n",
    "target_column = 'TARGET'\n",
    "\n",
    "X = df_application_train[input_columns]\n",
    "y = df_application_train[target_column]\n",
    "gc.collect()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train, num_feature = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = xgb.DMatrix(X_train, y_train)\n",
    "xgb_eval  = xgb.DMatrix(X_test, y_test)\n",
    "\n",
    "xgb_test   = xgb.DMatrix(df_application_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Params for the Hyperopt algo\n",
    "N_HYPEROPT_PROBES = 8 # #Number of evaluation cycles\n",
    "HYPEROPT_ALGO = tpe.suggest  # #Tree-of-Parzen-Estimators algo\n",
    "\n",
    "# #Params for XGBoost CV\n",
    "NUM_BOOST_ROUNDS = 270\n",
    "NB_CV_FOLDS = 10\n",
    "EARLY_STOPPING = 200\n",
    "HOLDOUT_SIZE = 0.20\n",
    "# HOLDOUT_SEED = 123456\n",
    "# SEED0 = random.randint(1,1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_call_count = 0\n",
    "cur_best_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    # #Global Variable Definition\n",
    "    global obj_call_count, cur_best_score, X_train, y_train, test, X_val, y_val\n",
    "\n",
    "    obj_call_count += 1\n",
    "    print('\\nXGBoost objective call #{} cur_best_score={:7.5f}'.format(obj_call_count,cur_best_score))\n",
    "\n",
    "    sorted_params = sorted(space.items(), key=lambda z: z[0])\n",
    "    print('Params:', str.join(' ', ['{}={}'.format(k, v) for k, v in sorted_params if not k.startswith('column:')]))\n",
    "\n",
    "\n",
    "    xgb_params = sample(space)\n",
    "    model = xgb.cv(xgb_params, xgb_train,\n",
    "                   num_boost_round = NUM_BOOST_ROUNDS,\n",
    "                    nfold=NB_CV_FOLDS,\n",
    "                    stratified=False,\n",
    "                    early_stopping_rounds=EARLY_STOPPING,\n",
    "                    verbose_eval=100,\n",
    "                    show_stdv=False)\n",
    "\n",
    "    n_rounds = len(model[\"test-auc-mean\"])\n",
    "    cv_score = model[\"test-auc-mean\"][n_rounds-1]\n",
    "    print('CV finished n_rounds={} cv_score={:7.5f}'.format(n_rounds, cv_score ))\n",
    "    \n",
    "    xgb_model = xgb.train(\n",
    "                        xgb_params,\n",
    "                        xgb_train,\n",
    "                        num_boost_round=n_rounds,\n",
    "                        verbose_eval=True)\n",
    "    \n",
    "    predictions = xgb_model.predict(xgb_eval, ntree_limit =n_rounds)\n",
    "    score = roc_auc_score(y_test, predictions)\n",
    "    print('valid score={}'.format(score))\n",
    "    \n",
    "    if score > cur_best_score:\n",
    "        cur_best_score = score\n",
    "        print('NEW BEST SCORE={}'.format(cur_best_score))\n",
    "       \n",
    "    loss = 1 - score\n",
    "    return {'loss': loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #NOTE: Any change in `space`, needs to be changed in xgb_default_params as well\n",
    "space ={\n",
    "    'booster '    : 'gbtree',       \n",
    "    'objective'   : 'binary:logistic',\n",
    "    'eval_metric' : 'auc',\n",
    "    'seed'        : 42,\n",
    "    'silent'      : 0,      #Messages would be printed\n",
    "    'n_thread'    : -1,     #-1: all cores are used\n",
    "    'subsample'   : 0.8,\n",
    "    'colsample_bytree': 0.7,\n",
    "    \n",
    "    'eta'         : hp.uniform('eta', 0.025, 0.25),   # #Learning rate - Step size shrinkage to handle overfitting\n",
    "    'min_child_weight': hp.choice(\"min_child_weight\", np.arange(5, 15,dtype=int)), # #Tradeoff b/n over and underfitting\n",
    "    'max_depth'   : hp.choice(\"max_depth\", np.arange(4, 8,dtype=int)), # #Tradeoff b/n over and underfitting\n",
    "    'alpha'       : hp.uniform('alpha', 0.5, 5), # #L1 regularization term - increase this value will make model more conservative.\n",
    "    'lambda'      : hp.uniform('lambda', 0.5, 5), # #L2 regularization term - increase this value will make model more conservative.\n",
    "    'gamma'       : hp.uniform('gamma', 0.6, 0.8),\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Trials keep track of all the experiments\n",
    "trials = Trials()\n",
    "\n",
    "# #MAIN function to run all the experiments\n",
    "best = fmin(fn=objective,\n",
    "                     space=space,\n",
    "                     algo=HYPEROPT_ALGO,\n",
    "                     max_evals=N_HYPEROPT_PROBES,\n",
    "                     trials=trials,\n",
    "                     verbose=1)\n",
    "\n",
    "\n",
    "print('-'*50)\n",
    "print('The best params:')\n",
    "print( best )\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #LB: 0.779\n",
    "xgb_params = {\n",
    " 'alpha': 3.160842634951819, # #This was 20 earlier\n",
    " 'booster ': 'gbtree',\n",
    " 'colsample_bytree': 0.7,\n",
    " 'eta': 0.1604387053222455,\n",
    " 'eval_metric': 'auc',\n",
    " 'gamma': 0.6236454630290655, # #This was 0.85 earlier\n",
    " 'lambda': 4.438488456929287, \n",
    " 'max_depth': 4,\n",
    " 'min_child_weight': 9,\n",
    " 'n_thread': -1,\n",
    " 'objective': 'binary:logistic',\n",
    " 'seed': 42,\n",
    " 'silent': 0,\n",
    " 'subsample': 0.8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Final Model\n",
    "gc.collect()\n",
    "watchlist = [(xgb.DMatrix(X_train, y_train), 'train'), (xgb.DMatrix(X_test, y_test), 'valid')]\n",
    "model = xgb.train(xgb_params, xgb.DMatrix(X, y), 270, watchlist, maximize=True, verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = model.predict(xgb.DMatrix(df_application_test), ntree_limit=model.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission[\"SK_ID_CURR\"] =  df_application_test[\"SK_ID_CURR\"]\n",
    "submission[\"TARGET\"] =  df_predict\n",
    "\n",
    "submission.to_csv(\"../submissions/model_1_xgbstarter_updatedParams_v8.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Should be 48744, 2\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 20,               # #Types of cuisine\n",
    "    'metric': {'multi_error'},\n",
    "    'num_leaves': 60,\n",
    "    'learning_rate': 0.06,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "d_valid = lgb.Dataset(X_valid, y_valid, reference=d_train)\n",
    "\n",
    "model_lgb = lgb.train(params, \n",
    "                d_train,\n",
    "                num_boost_round=1000,\n",
    "                valid_sets=d_valid,\n",
    "                verbose_eval=100,\n",
    "                early_stopping_rounds=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Predict\n",
    "y_pred = model_lgb.predict(X_test, num_iteration=gbm.best_iteration).argmax(axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
