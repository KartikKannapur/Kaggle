{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MXNet - Gluon Code Snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import autograd, nd\n",
    "\n",
    "# #Gluon data module to read data\n",
    "from mxnet.gluon import data as gdata\n",
    "\n",
    "# #Neural Network Layers\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "# #Model Parameter Initalizer\n",
    "from mxnet import init\n",
    "\n",
    "# #Gluon module to define loss functions\n",
    "from mxnet.gluon import loss as gloss\n",
    "\n",
    "# #Optimization Algorithm\n",
    "from mxnet.gluon import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X: features\n",
    "y: labels\n",
    "\"\"\"\n",
    "# #Combining the features and labels into a training set\n",
    "dataset = gdata.ArrayDataset(features, labels)\n",
    "\n",
    "# #Randomly reading data in batches - Mini Batch\n",
    "batch_size = 10\n",
    "data_iter = gdata.DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Sequential Container\n",
    "net = nn.Sequential()\n",
    "# #Adding a Dense layer with a scalar output\n",
    "net.add(nn.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Initialize Model Parameters\n",
    "\"\"\"\n",
    "Each weight parameter element is randomly sampled at\n",
    "initialization from a normal distribution with zero \n",
    "mean and sigma standard deviation.\n",
    "\n",
    "The bias parameter is initialized to zero by default\n",
    "\"\"\"\n",
    "net.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Each layer of the network can be selected via indexing - net[i]\n",
    "net[0]\n",
    "\n",
    "# #The weights and biases in each layer of the network\n",
    "w = net[0].weight.data()\n",
    "b = net[0].bias.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = gloss.L2Loss() # #Squared Loss or L2-norm loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define the Optimization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Algo: Mini-batch Stochastic Gradient Descent Algorithm\n",
    "\"\"\"\n",
    "The optimization algorithm will iterate over all parameters present\n",
    "in the network\n",
    "\"\"\"\n",
    "trainer = Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.03})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "* For a pre-defined number of epochs, we make a pass\n",
    "over the dataset that has been sampled via mini-batching\n",
    "the features(X) and the labels(y)\n",
    "* Then, for each mini-batch:\n",
    "- make prediction via `net(X)` and compare it to the label\n",
    "y and compute the loss function in the forward pass\n",
    "- compute gradients via backward pass\n",
    "- update the model parameters via SGD in the `trainer()` method\n",
    "\"\"\"\n",
    "\n",
    "num_epochs = 3\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in data_iter:\n",
    "        with autograd.record():\n",
    "            l = loss(net(X), y)\n",
    "        l.backward()\n",
    "        trainer.step(batch_size)\n",
    "    l = loss(net(features), labels)\n",
    "    print('epoch %d, loss: %f' % (epoch, l.mean().asnumpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute the error in estimating the weights and biases\n",
    "\"\"\"\n",
    "w = net[0].weight.data()\n",
    "print('Error in estimating w', true_w.reshape(w.shape) - w)\n",
    "b = net[0].bias.data()\n",
    "print('Error in estimating b', true_b - b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
